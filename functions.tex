\section{Using functions with equal numbers of parameters} % 5 pages
\label{sec:functions}

The simplest application of the envelope method is to the case where all
functions used have the same number of parameters.

\subsection{Function definitions}
\label{sec:functions:function}

The first study presented uses four functions, each of which has two parameters.
These functions are chosen as they, and their higher order equivalents,
are feasible representations of the background shape seen in the Higgs to two photon
analysis. The functions are detailed below; in each case $p_0$ and $p_1$ are
the two parameters.
\begin{enumerate}
\item
``Power law''; $f(x) = p_0 x^{p_1}$.
\item
``Exponential''; $f(x) = p_0 e^{p_1x}$.
\item
``Laurent''; $f(x) = p_0/x^4 + p_1/x^5$.
\item
``Polynomial''; $f(x) = p_0 + p_1 x$.
\end{enumerate}

\subsection{Example case}
\label{sec:functions:example}

In the CMS Higgs to two photon analysis, the discrete profiling method is applied to
the actual data taken by the CMS experiment. The variable used for the fit is the invariant mass of the two photons, $m_{\gamma\gamma}$.
The likelihood fit is performed to the $m_{\gamma\gamma}$ spectrum simultaneously
across different event categories\footnote{Categorising events with different signal to background ratios improves the sensitivities
of the analysis but presents additional complications beyond the scope of this study.}.
However, for the purposes of this
paper, the ``data'' used to illustrate the method are generated by a Monte Carlo
method from a smooth background
function which is similar in shape and magnitude to the
real data obtained in one particular category of that analysis. We emphasise that this is not the
actual data sample so that none of the detailed results presented below can be used to deduce any
properties of the Higgs boson itself.
This dataset was generated in 160 bins between 110 and 150\,GeV in
the mass variable, $m_{\gamma\gamma}$.
It included signal events
generated according to a Gaussian distribution with a normalization of 50.8 events, a mean of 125\,GeV and a
width of 1.19\,GeV. These values are representative of the expected Higgs signal from a single category of the
Higgs to two photon analysis.
In the following, the signal strength results are given in
terms of the relative strength $\mu$,
meaning the ratio of the measured number of the signal events relative
to the expected number.

The four two-parameter functions mentioned above were each
separately fitted to the dataset. A Gaussian signal component was also included, where the
mean and width of the Gaussian were fixed to the same values as used to
generate the events.
The magnitude of the signal Gaussian and both parameters in the
background function were determined from the fit.
The results are shown in figure~\ref{fig:functions:bestfits}.
It is clear that the first order polynomial does not fit particularly well,
while the other three functions give reasonable fits.
%
\begin{figure}[tbp]
\centering
\includegraphics[width=0.46\textwidth]{functions/BestFits.pdf}
\caption{Best fits of the four two-parameter functions (described in the
text).
%The dashed lines indicate the background component of the fit while the solid
%lines include the signal component.
The Laurent function is effectively identical to the power law function
and so is hidden underneath the power law line.
Note, for clarity in this plot, the
data have been rebinned into 40 bins, although the fits were performed with
finer binning of 160 bins.}
\label{fig:functions:bestfits}
\end{figure}

The profile scan as a function of the relative signal strength $\mu$
between $-1.0$ and 2.5
for the four functions is shown in
figure~\ref{fig:functions:profiles}.
The absolute minimum occurs for the power law function at a relative signal
strength of $\mu = 0.93$, for which the function parameters have the values
$p_0 = 2.24\times 10^{12}$ and $p_1 = -4.91$.
If only this function is considered,
the 68.3\% confidence interval on $\mu$ is
$0.43 < \mu < 1.40 $, determined as the interval for which $\Delta{\rm \nll} = \nll - \nll_{BF} < 1$.
The measurement would therefore be reported with its standard error as $\mu=0.93^{+0.47}_{-0.50}$. The Laurent function gives an identical result within the precision given.
If only the exponential function is considered, a slightly higher
\nll value is obtained
at the best fit point, which corresponds to a relative signal strength of $\mu = 0.72$, with parameters $p_0 = 1.45 \times 10^4$ and $p_1 = -0.0386$.
The 68.3\% confidence interval is
$0.27 < \mu < 1.24 $, equivalently written as $\mu = 0.72^{+0.52}_{-0.45}$.
Fitting with the straight line yields a very different result of
$\mu = 0.01^{+0.51}_{-0.47}$
although it is clear that this function does not describe the data well and it
gives a much larger \nll value.
The fact that the different functions can give different best fit values
is a direct example of the systematic uncertainty associated
with the choice of function.
%
\begin{figure}[tbp]
\centering
\includegraphics[width=0.46\textwidth]{functions/Profiles.pdf}
\caption{Profile \nll scans for the four two-parameter
functions discussed in the text.
The polynomial function is above the top of the \nll scale for all
$\mu$ values shown in this figure. }
\label{fig:functions:profiles}
\end{figure}

The envelope around these functions is shown in
figure~\ref{fig:functions:envelope}.
By construction, the best fit is still $\mu=0.93$ from the power law
but now the standard error is enlarged by the contribution from the exponential function
on the lower side of the scan. Hence, taking all four functions into
account, the 68.3\% confidence interval on $\mu$ is
$0.37 < \mu < 1.40 $, i.e.~the lower limit is extended by
the exponential fit
%and the upper limit is extended by the power law fit.
compared with the power law fit alone.
The measured value of $\mu$ would now be quoted as
$\mu = 0.93_{-0.56}^{+0.47}$.
The enlarged uncertainty is a direct reflection of the
systematic error arising from the uncertainty on the choice of function.
As also shown in figure~\ref{fig:functions:envelope}, the 95.4\% confidence
interval is $-0.18 < \mu < 1.92$.
There are two things to note. Firstly, although the Laurent fit
is effectively identical to the power law, there is no issue with
``double-counting'' as the envelope just takes the lowest \nll.
Also, it is clear that the poor fit of the polynomial
means it plays no role in the envelope and so this function is
``automatically'' ignored by the method,
without requiring any arbitrary criterion for
including it or not.
%
\begin{figure}[tbp]
\centering
\includegraphics[width=0.46\textwidth]{functions/Envelope.pdf}
\caption{Profile \nll envelope for the four two-parameter function fits.
The coloured bands indicate the 68.3\% and 95.4\% intervals determined from the regions
for which the value of \nll increases by 1 and 4 units from the minimum value as indicated by the horizontal lines. The dashed red line shows the profile \nll
curve which would be obtained using just the power law function.}
\label{fig:functions:envelope}
\end{figure}


%\subsection{Bias and coverage}
\subsection{Checks of the method}
\label{sec:functions:coverage}

%The bias and coverage
Properties of this method were studied
using a large ensemble of
pseudo-experiments (``toys''). In each pseudo-experiment, a
dataset including signal and background events was generated using a Monte Carlo technique.
Ensembles were generated %, and consequently the bias and coverage properties tested, 
under various different background hypotheses and for different values of the signal strength, $\mu$.
The resulting toy datasets are treated identically to the original dataset.

The background function from which the Monte Carlo events were generated was chosen to be one of the power law,
exponential or Laurent two-parameter functions discussed in
Section~\ref{sec:functions:function}. The background parameters for generating the toys are set to their best fit values for the given value of $\mu$.

In addition, a further ensemble of toy datasets was generated, for which the background function itself, as well
as its parameters, was chosen according to the best fit (i.e.~the function minimizing \nll) for each value of $\mu$.
As can be seen from figure~\ref{fig:functions:profiles}, this means that for values of $\mu < 0.55$ the exponential background
function will be used and it will be a power law function otherwise.
Conceptually, this method again
treats the choice of function as a discrete nuisance parameter and so picks the
best fit values of {\em all\/} nuisance parameters for each $\mu$ value.

Using the toy ensembles, a check was made of the change of the value of \nll between the best fit value and the value at the true value of $\mu$.
Under the asymptotic approximation, this difference would be the same as a $\chi^2$ 
distribution with one degree of freedom.
Figure~\ref{fig:functions:chisq} shows an example of such a distribution. It is seen that it is close to the
expected $\chi^2$ distribution, whether the best fit yields the same function as used to generate the toy dataset
or yields a different function. It is seen this is true even though the best fit function is more often different from the generated function rather than being
the same.
This example is typical; checking all the functions used to generate the toy datasets, the toy fits give the same conclusion.
This indicates that the actual function which contributes to the envelope is not
an important factor in obtaining a correct result, 
and hence treating the function used as a nuisance parameter (i.e.~one for 
which the value is not important) is a sensible approach. 
%
\begin{figure}[tbp]
\centering
\includegraphics[width=0.46\textwidth]{functions/gen_pow1_mu1_bias_hists_2parfamily_Correcion_0.pdf}
\caption{Distribution of the difference of \nll between the \nll value with $\mu$ fixed to its true value and \nll at the best fit value
of $\mu$. These values are from fits to toy datasets generated with the power law function, for which the parameters are fixed to the best fit values as described in the previous section.
%as described in Sec.~\ref{sec:functions:example}. 
The black data points are from the toy dataset fits and the green function
shows the expected $\chi^2$ distribution for one degree of freedom. The blue and red histograms show the toy values separated into
cases where the best fit uses the same or different functions, respectively, compared with the function used to generate the toys.}
\label{fig:functions:chisq}
\end{figure}

The same toy datasets are also used to check the bias and coverage.
These are assessed by calculating the fitted signal strength, $\mu$, and its error, $\sigma$, for each toy when using different background models. The background functions fitted to the toy datasets were the four two-parameter functions discussed.
We define the bias as the mean of the pull distribution, where the pull for an individual toy dataset is defined as
\begin{displaymath}
	p(\mu,\sigma) = \frac{\hat{\mu}-\mu}{\sigma},
\end{displaymath}
where $\mu$ is the generated value of the signal strength, $\hat{\mu}$ is the fitted value of $\mu$ per toy and $\sigma$ is the positive error on $\hat{\mu}$ if $\hat{\mu} < \mu$ and is the negative error on $\hat{\mu}$ if $\hat{\mu} > \mu$. The results of the mean pull as a function of the generated signal strength are shown in figure~\ref{fig:functions:firstorderbias}. It can be seen, as one would expect, that when fitting back with the same background function as used to generate the toy dataset, the bias is negligible. It is also shown that the bias is not dependent on the value of $\mu$ used to generate the signal. However, when fitting back with a different background function the bias can be large; here giving a mean pull up to 0.5.
The discrete profiling method provides a medium between these two in which the bias is small (a mean pull of around 0.1) regardless of the generating function used. This is important given that this method is to be applied when the true underlying function is unknown.
%
\begin{figure}[tbp]
\centering
\includegraphics[width=0.8\textwidth]{functions/FirstOrderFunctions.pdf}
\caption{Average pull when fitting with each function as background and when
using the discrete profiling method. Panels (a), (b) and (c) show the results
when the generating background function is the power law, exponential and Laurent,
respectively. Panel (d) shows the result when the best-fit function at each
value of $\mu$ is used to generate toys; this means the exponential function
below $\mu = 0.55$ and the power law function above this value. Within each panel the different
points correspond to a different fitting function: Laurent (solid green), power law (open blue), exponential (open red) and the envelope of all four two-parameter functions (solid black). In all cases,
fitting with the polynomial gives values outside the range of these plots.}
\label{fig:functions:firstorderbias}
\end{figure}

The coverage was tested, using the same fits, by determining the frequency with which the difference in \nll between the best fit value $\hat{\mu}$ and the value $\mu$ used to generate the signal was more than 0.25, 1, 4 and 9.
%These frequencies were compared with the expected frequencies, 38.3\%, 68.3\%, 95.4\% and 99.7\% respectively.
These were converted to a two-sides scoe $|Z|$ and
compared with the expected intervals from a Gaussian distribution, namely
0.5, 1, 2 and 3 times the Gaussian width, respectively.
The results for these are shown in figure~\ref{fig:functions:firstordercoverage}. It can be seen that when the fitting function is different from the generating function the calculated confidence interval can undercover, whereas when using the discrete profiling method the coverage is good regardless of the generating function. The coverage is found to be good,
independent of the value of $\mu$ used to generate the signal.
%
\begin{figure}[tbp]
\centering
  \subfigure[]{\includegraphics[width=0.4\textwidth]{{functions/FirstOrderFunctions_Coverage_0.5}.pdf}
\label{fig:functions:firstordercoverage:a}}
  \subfigure[]{\includegraphics[width=0.4\textwidth]{{functions/FirstOrderFunctions_Coverage_1.}.pdf}
\label{fig:functions:firstordercoverage:b}}\\
  \subfigure[]{\includegraphics[width=0.4\textwidth]{{functions/FirstOrderFunctions_Coverage_2.}.pdf}
\label{fig:functions:firstordercoverage:c}}
  \subfigure[]{\includegraphics[width=0.4\textwidth]{{functions/FirstOrderFunctions_Coverage_3.}.pdf}
\label{fig:functions:firstordercoverage:d}}
\caption{Measure of the fraction of the toys which do not contain the generated
$\mu$ in various specified $\Lambda$ intervals, converted
into the two-sided score $|Z|$ in units of the equivalent Gaussian width.
The intervals are
$\Delta\Lambda$ of 0.25 (a), 1.0 (b), 4.0 (c) and 9.0 (d).
These results are obtained by fitting using a single
function and using the envelope.
Within each subfigure,
the first, second and third plots shows the results
when the generating background function is the power law, exponential and Laurent,
respectively. The last plot in each subfigure
shows the result when the best-fit function at each
value of $\mu$ is used to generate toys. Within each panel the different
points correspond to a different fitting function: Laurent (solid green), power law (open blue), exponential (open red) and the envelope of all four two-parameter functions (solid black). In all cases,
fitting with the polynomial gives values outside the range of these plots.}
\label{fig:functions:firstordercoverage}
\end{figure}


%ASIMOV RESULTS AS PART OF DISCUSSION ON BIAS?

%UNBINNED MENTIONED ONLY IN PASSING


%\subsection{Toy generation}
%\label{sec:functions:toys}

%WHAT IS A BETTER TERM THAN ``TOYS''?

%1. USING SINGLE FUNCTION (GIVING BIAS)

%2. USING BAYESIAN PROBABILITY MIX OF FUNCTIONS (NO BIAS)

%3. USING FREQUENTIST FRACTIONAL CONTRIBUTIONS OF FUNCTIONS (BIAS???)
